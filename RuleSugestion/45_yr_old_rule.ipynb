{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the datasets I built in the preprocessing notebook\n",
    "play_information = feather.read_dataframe('../input/nflpuntpreprocessed/play_information.feather')\n",
    "game_data = feather.read_dataframe('../input/nflpuntpreprocessed//game_data.feather')\n",
    "play_player_role_data = feather.read_dataframe('../input/nflpuntpreprocessed/play_player_role_data.feather')\n",
    "min_distances = feather.read_dataframe('../input/nflpuntpreprocessed/min_distances.feather')\n",
    "second_min_distances = feather.read_dataframe('../input/nflpuntpreprocessed/second_min_distances.feather')\n",
    "punt_hangtime = feather.read_dataframe('../input/nflpuntpreprocessed/punt_hangtime.feather')\n",
    "video_review = feather.read_dataframe('../input/nflpuntpreprocessed/video_review.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a master play-level dataset\n",
    "aug_play_information = play_information.merge(\n",
    "    min_distances[['GameKey', 'PlayID', 'Coverage_Distance']],\n",
    "    on=['GameKey', 'PlayID'], how='left', validate='one_to_one'\n",
    ").merge(\n",
    "    second_min_distances[['GameKey', 'PlayID', 'Coverage_Distance']],\n",
    "    on=['GameKey', 'PlayID'], how='left', validate='one_to_one',\n",
    "    suffixes=['_1', '_2']\n",
    ").merge(\n",
    "    game_data[['GameKey', 'Temperature', 'Is_Grass', 'Is_Outdoor']] ,\n",
    "    on=['GameKey'], how='left', validate='many_to_one'\n",
    ").merge(\n",
    "    punt_hangtime[['GameKey', 'PlayID', 'Hangtime']],\n",
    "    on=['GameKey', 'PlayID'], how='left', validate='one_to_one'\n",
    ").merge(\n",
    "    video_review,\n",
    "    on=['GameKey', 'PlayID'], how='left', validate='one_to_one',\n",
    ")\n",
    "\n",
    "aug_play_information['Has_Concussion'] = ~aug_play_information.GSISID.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays_with_punts = aug_play_information[aug_play_information.Has_Punt]\n",
    "plays_with_concussions = aug_play_information[aug_play_information.Has_Concussion]\n",
    "\n",
    "print(\"Total plays:\", aug_play_information.shape[0])\n",
    "print(\"Plays with a punt:\", plays_with_punts.shape[0])\n",
    "print(\"Plays with a concussion:\", plays_with_concussions.shape[0])\n",
    "print(\"Plays with a punt and a concussion:\", plays_with_concussions[plays_with_concussions.Has_Punt].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays_with_concussions = plays_with_concussions[plays_with_concussions.Has_Punt]\n",
    "\n",
    "concussion_rates = plays_with_concussions.Punt_Type.value_counts() / plays_with_punts.Punt_Type.value_counts()\n",
    "ax = concussion_rates.plot(\n",
    "    kind='barh', figsize=(10,5), color='#2678B2', fontsize=12,\n",
    "    title='Concussions Occur Over 7x More Often On Returned Punts')\n",
    "vals = ax.get_xticks()\n",
    "ax.set(xlabel=\"Concussion Rate\", xticklabels=['{:,.1%}'.format(x) for x in vals]);\n",
    "ax.xaxis.label.set_size(14)\n",
    "ax.title.set_size(16)\n",
    "\n",
    "ttest_res = ttest_ind(\n",
    "    plays_with_punts[plays_with_punts.Has_Return].Has_Concussion, \n",
    "    plays_with_punts[~plays_with_punts.Has_Return].Has_Concussion\n",
    ")\n",
    "\n",
    "if ttest_res.pvalue < .05:\n",
    "    print('The difference in concussion rates on plays with and without returns is statistically significant.')\n",
    "else:\n",
    "    print('The difference in concussion rates on plays with and without returns is not statistically significant.')\n",
    "print('p-value:', '%f' % ttest_res.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays_with_return = plays_with_punts[plays_with_punts.Has_Return]\n",
    "plays_with_fair_catch = plays_with_punts[plays_with_punts.Has_Fair_Catch]\n",
    "\n",
    "label = ['Has_Fair_Catch']\n",
    "\n",
    "features = [\n",
    "    'Punt_Distance', 'Time_Passed_Sec', 'Score_Differential',\n",
    "    'Yard_Line_Absolute', 'Coverage_Distance_1', 'Coverage_Distance_2',\n",
    "    'Hangtime', 'Temperature', 'Is_Grass', 'Is_Outdoor'\n",
    "]\n",
    "\n",
    "plays_with_return_or_fc = pd.concat(\n",
    "    [plays_with_return, plays_with_fair_catch]\n",
    ")[['GameKey', 'PlayID'] + features + label].dropna()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(plays_with_return_or_fc[features]),\n",
    "    np.array(plays_with_return_or_fc[label]).ravel(),\n",
    "    test_size=0.2,\n",
    "    random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[10, 50, 100],\n",
    "    'learning_rate': [.01, .05, .1],\n",
    "    'max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(GradientBoostingClassifier(random_state=0), parameters, cv=3)\n",
    "search.fit(x_train, y_train)\n",
    "\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best params from grid-search above\n",
    "gbdt = GradientBoostingClassifier(\n",
    "    n_estimators=search.best_params_['n_estimators'],\n",
    "    learning_rate=search.best_params_['learning_rate'],\n",
    "    max_depth=search.best_params_['max_depth'],\n",
    "    random_state=0\n",
    ").fit(x_train, y_train)\n",
    "\n",
    "y_scores_gbdt = gbdt.predict_proba(x_test)[:,1]\n",
    "\n",
    "print(\"Train accuracy: {:,.1%}\".format(gbdt.score(x_train, y_train)))\n",
    "print(\"Test accuracy: {:,.1%}\".format(gbdt.score(x_test, y_test)))\n",
    "print(\"ROC AUC: {:,.3f}\".format(roc_auc_score(y_test, y_scores_gbdt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(\n",
    "    gbdt.feature_importances_,\n",
    "    index = features,\n",
    "    columns=['importance']\n",
    ").sort_values('importance', ascending=True).plot(\n",
    "    title='Fair-Catch Model Feature Importances', kind='barh', legend=False, figsize=(10,5), fontsize=12\n",
    ")\n",
    "\n",
    "ax.title.set_size(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=2).fit(x_train, y_train)\n",
    "y_scores_logreg = logreg.predict_proba(x_test)[:,1]\n",
    "y_pred_logreg = logreg.predict(x_test)\n",
    "\n",
    "print(\"Train accuracy:\",logreg.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", logreg.score(x_test, y_test))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_scores_logreg))\n",
    "\n",
    "ax = pd.DataFrame(\n",
    "    logreg.coef_.transpose(),\n",
    "    index=features,\n",
    "    columns=['coefficients']\n",
    ").sort_values('coefficients').plot(\n",
    "    kind='barh', legend=False, title='Logistic Regression Feature Coefficients', figsize=(10,5), fontsize=14\n",
    ")\n",
    "\n",
    "ax.title.set_size(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coverage_distance(row):\n",
    "    snap_to_punt_time_adjustment = .5 # Percentage of blocking time converted to coverage time\n",
    "    minimal_coverage_distance = .5 # don't let adjusted coverage distance get smaller than half a yard\n",
    "    if 'GL' in row.Role_k or 'GR' in row.Role_k:\n",
    "        return row.Coverage_Distance\n",
    "    else:\n",
    "        return max(\n",
    "            row.Coverage_Distance - (\n",
    "                row.Yards_Per_Second * (\n",
    "                    row.Snap_To_Punt_time * snap_to_punt_time_adjustment\n",
    "                )\n",
    "            ), minimal_coverage_distance\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Adjusted Coverage Distances\n",
    "adjusted_coverage_distances = feather.read_dataframe('../input/nflpuntpreprocessed/adjusted_coverage_distances.feather')\n",
    "\n",
    "adjusted_coverage_distances['Adj_Coverage_Distance'] = adjusted_coverage_distances.apply(\n",
    "    update_coverage_distance, axis=1\n",
    ")\n",
    "\n",
    "min_acd = adjusted_coverage_distances.loc[\n",
    "    adjusted_coverage_distances.groupby(['GameKey', 'PlayID'])['Adj_Coverage_Distance'].idxmin()\n",
    "][['GameKey', 'PlayID', 'Adj_Coverage_Distance', 'Role_k', 'Super_Role_k']]\n",
    "\n",
    "adjusted_coverage_distances_2 = adjusted_coverage_distances.drop(\n",
    "    adjusted_coverage_distances.groupby(['GameKey', 'PlayID'])['Adj_Coverage_Distance'].idxmin()\n",
    ")\n",
    "\n",
    "second_min_acd = adjusted_coverage_distances_2.loc[\n",
    "    adjusted_coverage_distances_2.groupby(['GameKey', 'PlayID'])['Adj_Coverage_Distance'].idxmin()\n",
    "][['GameKey', 'PlayID', 'Adj_Coverage_Distance', 'Role_k', 'Super_Role_k']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame({\n",
    "    \"Before Rule Change\": min_distances.Super_Role_k.value_counts() / min_acd.shape[0],\n",
    "    \"After Rule Change\": min_acd.Super_Role_k.value_counts() / min_acd.shape[0]\n",
    "}).plot(kind='barh', figsize=(10,5), title='Nearest Coverage Team Member At Time Of Punt Reception')\n",
    "\n",
    "vals = ax.get_xticks()\n",
    "ax.set(xlabel=\"% of Plays\", xticklabels=['{:,.0%}'.format(x) for x in vals])\n",
    "\n",
    "ax.title.set_size(16)\n",
    "ax.xaxis.label.set_size(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model on new adjusted coverage distance features\n",
    "adj_features = [\n",
    "    'Punt_Distance', 'Time_Passed_Sec', 'Score_Differential',\n",
    "    'Yard_Line_Absolute', 'Adj_Coverage_Distance_1', 'Adj_Coverage_Distance_2',\n",
    "    'Hangtime', 'Temperature', 'Is_Grass', 'Is_Outdoor'\n",
    "]\n",
    "\n",
    "adj_X = plays_with_return_or_fc.merge(\n",
    "    min_acd, on=['GameKey', 'PlayID'], how='inner', validate='one_to_one'\n",
    ").merge(\n",
    "    second_min_acd, on=['GameKey', 'PlayID'], how='inner', validate='one_to_one', suffixes=[\"_1\", \"_2\"]\n",
    ")\n",
    "\n",
    "adj_X['Adj_Has_Fair_Catch_pred'] = gbdt.predict(adj_X[adj_features]) | adj_X.Has_Fair_Catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_plays_with_punts = plays_with_punts.merge(\n",
    "    adj_X[['GameKey', 'PlayID', 'Adj_Has_Fair_Catch_pred']],\n",
    "    on=['GameKey', 'PlayID'], how='left', validate='one_to_one'\n",
    ")\n",
    "\n",
    "adj_plays_with_punts['Adj_Punt_Type'] = adj_plays_with_punts.apply(\n",
    "    lambda row:\n",
    "        row.Punt_Type\n",
    "        if pd.isna(row.Adj_Has_Fair_Catch_pred)\n",
    "        else (\n",
    "            'fair catch'\n",
    "            if row.Adj_Has_Fair_Catch_pred\n",
    "            else 'return'\n",
    "        )\n",
    "    , axis=1\n",
    ")\n",
    "adj_plays_with_punts['Adj_Has_Fair_Catch_pred'] = adj_plays_with_punts.Adj_Punt_Type == 'fair catch'\n",
    "adj_plays_with_punts['Adj_Punt_Return_Length'] = adj_plays_with_punts.apply(\n",
    "    lambda row:\n",
    "        row.Punt_Return_Length\n",
    "        if not row.Adj_Has_Fair_Catch_pred\n",
    "        else 0.0\n",
    "    , axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame({\n",
    "    \"(Estimated) After Rule Change\": adj_plays_with_punts.Adj_Punt_Type.value_counts() / adj_plays_with_punts.shape[0],\n",
    "    \"Before Rule Change\": adj_plays_with_punts.Punt_Type.value_counts() / adj_plays_with_punts.shape[0]\n",
    "}, index=adj_plays_with_punts.Punt_Type.unique()).transpose().plot(\n",
    "    kind='barh', title='Rule Change Increases Fair Catch Frequency from 25% to 40%', figsize=(10,5)\n",
    ")\n",
    "vals = ax.get_xticks()\n",
    "ax.set(xlabel=\"% of Plays\", xticklabels=['{:,.0%}'.format(x) for x in vals]);\n",
    "\n",
    "ax.xaxis.label.set_size(14)\n",
    "ax.title.set_size(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_concussions = adj_plays_with_punts.Has_Concussion.sum()\n",
    "post_concussions = (\n",
    "    adj_plays_with_punts.Has_Concussion & ~(\n",
    "        (adj_plays_with_punts.Punt_Type == 'return') & (adj_plays_with_punts.Adj_Punt_Type == 'fair catch')\n",
    "    )\n",
    ").sum()\n",
    "print(\"# Concussions Before Rule Change:\", pre_concussions)\n",
    "print(\"# Concussions After Rule Change:\", post_concussions)\n",
    "print(\"Percent Decrease in Concussions: {:,.1%}\".format((pre_concussions - post_concussions) / pre_concussions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_plays_with_punts['Next_Poss_Yard_Line'] = adj_plays_with_punts.apply(\n",
    "    lambda row:\n",
    "        np.nan\n",
    "        if row.Punt_Type == 'unreturnable'\n",
    "        else 100 - (row.Yard_Line_Absolute + row.Punt_Distance - row.Punt_Return_Length)\n",
    "    , axis=1\n",
    ")\n",
    "\n",
    "adj_plays_with_punts['Adj_Next_Poss_Yard_Line'] = adj_plays_with_punts.apply(\n",
    "   lambda row:\n",
    "        np.nan\n",
    "        if row.Adj_Punt_Type == 'unreturnable'\n",
    "        else 100 - (row.Yard_Line_Absolute + row.Punt_Distance - row.Adj_Punt_Return_Length)\n",
    "    , axis=1\n",
    ")\n",
    "\n",
    "adj_plays_with_returnable_punts = adj_plays_with_punts[\n",
    "    adj_plays_with_punts.Has_Return | adj_plays_with_punts.Has_Fair_Catch\n",
    "]\n",
    "\n",
    "ax = pd.DataFrame(\n",
    "    {\n",
    "        'Before Distribution':adj_plays_with_returnable_punts.Next_Poss_Yard_Line,\n",
    "        'After Distribution': adj_plays_with_returnable_punts.Adj_Next_Poss_Yard_Line\n",
    "    }\n",
    ").plot(\n",
    "    kind='density', xlim=(0,100), ylim=(0,.03), figsize=(12,6),\n",
    "    title='Distribution of Receiving Team\\'s Starting Field Position',\n",
    ")\n",
    "\n",
    "before_mean_yard_line = adj_plays_with_returnable_punts.Next_Poss_Yard_Line.mean()\n",
    "after_mean_yard_line = adj_plays_with_returnable_punts.Adj_Next_Poss_Yard_Line.mean()\n",
    "\n",
    "yard_line_vals = [0,10,20,30,40,50,60,70,80,90,100]\n",
    "yard_line_labels = [\n",
    "    'Own Goal Line' if x == 0\n",
    "    else (\n",
    "        'Opp Goal Line' if x == 100\n",
    "        else (\n",
    "            x if x <= 50 \n",
    "            else 100-x\n",
    "        )\n",
    "    ) for x in yard_line_vals]\n",
    "ax.set(\n",
    "    xlabel=\"Yard Line\", xticks=yard_line_vals, xticklabels=yard_line_labels,\n",
    "    yticklabels= [''] + [str(x) for x in ax.get_yticks()[1:]]\n",
    ")\n",
    "plt.axvline(\n",
    "    before_mean_yard_line, linestyle='dashed', color='tab:blue', linewidth=2,\n",
    "    label='Before Mean: {:,.1f} yard line'.format(before_mean_yard_line)\n",
    ")\n",
    "plt.axvline(\n",
    "    after_mean_yard_line, linestyle='dashed', color='tab:orange', linewidth=2,\n",
    "    label='After Mean: {:,.1f} yard line'.format(after_mean_yard_line)\n",
    ")\n",
    "ax.xaxis.label.set_size(14)\n",
    "ax.title.set_size(16)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plays_with_return[['Punt_Return_Length', 'Coverage_Distance_1']].dropna()\n",
    "linregress_result = linregress(x.Coverage_Distance_1, x.Punt_Return_Length)\n",
    "print('R^2: {:,.3f}'.format(linregress_result.rvalue ** 2))\n",
    "print('P-value: {}'.format(linregress_result.pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exciting_return_length = 20\n",
    "\n",
    "print(\"Of All Punts (returnable and unreturnable)\")\n",
    "print(\"    Percent of total punt plays with >20 yard return before change: {:,.1%}\".format(\n",
    "    (adj_plays_with_punts.Punt_Return_Length > exciting_return_length).sum() / adj_plays_with_punts.shape[0]\n",
    "))\n",
    "print(\"    Percent of total punt plays with >20 yard return after change: {:,.1%}\".format(\n",
    "    (adj_plays_with_punts.Adj_Punt_Return_Length > exciting_return_length).sum() / adj_plays_with_punts.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
