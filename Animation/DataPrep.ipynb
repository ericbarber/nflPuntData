{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 29-30: malformed \\N character escape (<ipython-input-7-3e0160afeb90>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-3e0160afeb90>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    nddf = dd.read_csv('..\\AWS_VM\\nfl_punt_regulation\\NGS*',\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 29-30: malformed \\N character escape\n"
     ]
    }
   ],
   "source": [
    "ndtypes = {'GameKey': 'int16',         \n",
    "           'PlayID': 'int16',         \n",
    "           'GSISID': 'float32',        \n",
    "           'Time': 'str',         \n",
    "           'x': 'float32',         \n",
    "           'y': 'float32',         \n",
    "           'dis': 'float32',        \n",
    "           'Event': 'str'}\n",
    "\n",
    "nddf = dd.read_csv('../input/NFL-Punt-Analytics-Competition/NGS*', \n",
    "                usecols=[n for n in ndtypes.keys()], dtype=ndtypes)\n",
    "\n",
    "meta = ('Time', 'datetime64[ns]')\n",
    "nddf['Time'] = nddf.Time.map_partitions(pd.to_datetime, meta=meta)\n",
    "nddf['GSISID'] = nddf.GSISID.fillna(-1).astype('int32')\n",
    "\n",
    "nddf = nddf.compute()\n",
    "nddf.to_parquet('NGS.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get base data and role types\n",
    "players = pd.read_csv('../input/NFL-Punt-Analytics-Competition/play_player_role_data.csv')\n",
    "descrs = pd.read_csv('../input/nfl-competition-data/roledscrps.csv')\n",
    "players = players.merge(descrs, on='Role', how='left').drop('Season_Year',\\\n",
    "                        axis=1)\n",
    "\n",
    "# tag players involved in concussion events\n",
    "revs = pd.read_csv('../input/NFL-Punt-Analytics-Competition/video_review.csv', \n",
    "                   usecols=['GameKey', 'PlayID', \n",
    "            'GSISID', 'Primary_Partner_GSISID'], na_values=['Unclear'])\\\n",
    "            .fillna(-99).astype(int)\n",
    "players = players.merge(revs, how='left', on=['GameKey', 'PlayID', 'GSISID'],\\\n",
    "                        sort='False')\n",
    "players['concussed'] = np.where(players.Primary_Partner_GSISID.isnull(), 0, 1)\n",
    "\n",
    "players = players.merge(revs, how='left', left_on=['GameKey', 'PlayID', \n",
    "            'GSISID'], right_on=['GameKey', 'PlayID', \n",
    "            'Primary_Partner_GSISID'], suffixes=(\"\", \"_dupe\"), sort='False')\n",
    "players['concussor'] = np.where(players.Primary_Partner_GSISID_dupe.isnull()\n",
    "                        , 0, 1)\n",
    "\n",
    "# add numbers and positions\n",
    "playas = pd.read_csv('../input/NFL-Punt-Analytics-Competition/player_punt_data.csv')\n",
    "playas_agg = playas.groupby('GSISID')['Number'].apply(' '.join).to_frame()\n",
    "players = players.merge(playas_agg, on='GSISID', how='left')\n",
    "\n",
    "drops = ['Primary_Partner_GSISID'] + players.columns[players.columns.str\\\n",
    "        .contains('dupe')].tolist()\n",
    "players = players.drop(drops, axis=1).sort_values(['GSISID', 'GameKey', \n",
    "          'PlayID']).set_index('GSISID').reset_index()\n",
    "\n",
    "players.to_parquet('players.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% join play level and game level data\n",
    "plays = pd.read_csv('../input/NFL-Punt-Analytics-Competition/play_information.csv', \n",
    "                    index_col=['GameKey', 'PlayID'])\n",
    "\n",
    "games = pd.read_csv('../input/NFL-Punt-Analytics-Competition/game_data.csv', \n",
    "                    index_col=['GameKey'])\n",
    "games.Temperature.fillna(-999, inplace=True)\n",
    "plays_all = plays.join(games, rsuffix='_dupe', sort=False)\n",
    "\n",
    "revs = pd.read_csv('../input/NFL-Punt-Analytics-Competition/video_review.csv', \n",
    "                   index_col=['GameKey', 'PlayID'])\n",
    "revs.loc[revs.Primary_Partner_GSISID == 'Unclear', 'Primary_Partner_GSISID']\\\n",
    "             = np.nan\n",
    "revs['Primary_Partner_GSISID'] = pd.to_numeric(revs.Primary_Partner_GSISID)\n",
    "plays_all = plays_all.join(revs, rsuffix='_dupe2', sort=False)\n",
    "\n",
    "\n",
    "#%% merge player numbers and positions for concussions\n",
    "playernums = pd.read_csv('../input/NFL-Punt-Analytics-Competition/player_punt_data.csv')\n",
    "playernums = playernums.groupby('GSISID').agg(' '.join) #combine dupes\n",
    "\n",
    "plays_all = plays_all.reset_index().merge(playernums, how='left', on='GSISID', \n",
    "            sort=False)\n",
    "plays_all = plays_all.merge(playernums, how='left', \n",
    "            left_on='Primary_Partner_GSISID', right_on='GSISID', \n",
    "            suffixes=(\"_player\", \"_partner\"), sort=False)\n",
    "\n",
    "\n",
    "#%% merge player level data for concussions\n",
    "roles = pd.read_csv('../input/NFL-Punt-Analytics-Competition/play_player_role_data.csv')\n",
    "roles_all = roles.merge(descrs, on='Role', how='left').drop('Season_Year', \n",
    "                        axis=1)\n",
    "\n",
    "plays_all = plays_all.merge(roles_all, how='left', on=['GameKey', 'PlayID', \n",
    "            'GSISID'], sort=False)\n",
    "plays_all = plays_all.merge(roles_all, how='left', left_on=['GameKey', \n",
    "            'PlayID', 'Primary_Partner_GSISID'], right_on=['GameKey', \n",
    "            'PlayID', 'GSISID'], suffixes=(\"_player\", \"_partner\"), sort=False)\n",
    "\n",
    "plays_all.set_index(['GameKey', 'PlayID'], inplace=True)\n",
    "\n",
    "\n",
    "# merge aggregated player level data for all plays\n",
    "roles_enc = pd.get_dummies(roles_all, columns=['Team', 'Area', 'Type'])\n",
    "collist = list(roles_enc)[2:]\n",
    "agglist = ['size', pd.Series.nunique] + (len(collist)-3) * ['sum']\n",
    "aggdict = dict(zip(collist, agglist))\n",
    "\n",
    "\n",
    "roles_agg = roles_enc.groupby(['GameKey', 'PlayID']).agg(aggdict)\n",
    "roles_agg.columns = [r + '_agg' for r in roles_agg.columns]\n",
    "\n",
    "plays_all = plays_all.join(roles_agg, rsuffix=\"_roles\")\n",
    "\n",
    "\n",
    "#%% make simple features\n",
    "plays_all['yard_number'] = plays_all.YardLine.str.split().str[1].astype(int)\n",
    "plays_all['dist_togoal'] = np.where(plays_all.Poss_Team == plays_all.YardLine\\\n",
    "            .str.split().str[0], plays_all.yard_number + 50, \n",
    "            plays_all.yard_number)\n",
    "plays_all['Rec_team'] = np.where(plays_all.Poss_Team == plays_all.HomeTeamCode, \n",
    "             plays_all.VisitTeamCode, plays_all.HomeTeamCode)\n",
    "plays_all['home_score'] = plays_all.Score_Home_Visiting.str.split(\" - \")\\\n",
    "            .str[0].astype(int)\n",
    "plays_all['visit_score'] = plays_all.Score_Home_Visiting.str.split(\" - \")\\\n",
    "            .str[1].astype(int)\n",
    "plays_all['concussion'] = np.where(plays_all.Primary_Impact_Type.isnull(), \n",
    "                                    0, 1)\n",
    "\n",
    "#%% clean up \n",
    "drops = ['YardLine',\n",
    "         'Play_Type',\n",
    "         'Home_Team_Visit_Team',\n",
    "         'Primary_Partner_GSISID',\n",
    "         'Score_Home_Visiting']\\\n",
    "         + plays_all.columns[plays_all.columns.str.contains('dupe')].tolist()\n",
    "plays_all.drop(drops, axis=1, inplace=True)\n",
    "\n",
    "plays_all['GSISID_player'] = plays_all.GSISID_player.fillna(-99, \n",
    "                                downcast='infer')\n",
    "plays_all['GSISID_partner'] = plays_all.GSISID_partner.fillna(-99, \n",
    "                                downcast='infer')\n",
    "\n",
    "floatcols = plays_all.select_dtypes('float').columns\n",
    "for f in floatcols:\n",
    "    plays_all[f] = plays_all[f].fillna(-99).astype(int)\n",
    "\n",
    "plays_all.fillna('unspecified', inplace=True)\n",
    "plays_all.replace('SD', 'LAC', inplace=True, regex=True)\n",
    "plays_all['Game_Date'] = pd.to_datetime(plays_all.Game_Date, format='%m/%d/%Y')\n",
    "\n",
    "plays_all.sort_index(inplace=True)\n",
    "plays_all.reset_index(inplace=True) #avoid mulit-index for parquet\n",
    "\n",
    "plays_all.to_parquet('plays.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
